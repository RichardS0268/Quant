本项目基于《华泰人工智能》系列六进行复现。项目主要分为

1. 数据处理
2. 模型训练
3. 策略部署与回测

### 0. 策略主要思想

本策略的调仓频率为一个月，是主要思想利用XGBoost模型通过本地数据给出的10个feature来进行股票超额收益率的预测（比较基准为沪深三百指数），选取超额收益率最高的那部分，将其按照市值大小进行排序。然后再选取市值最小和最大的一部分进行资金分配。

### 1. 数据处理

**1.1 训练样本生成**

主要工作是将本地数据的组织形式进行修改，得到结构化的训练数据。该数据的entry为colums = 

['num_id','time','Capitalization','CirculatingCap','CirculatingMarketCap', 'MarketCap','PBRatio','PCFRatio','PSRatio','PeRatio','PeRatioLYR','TurnoverRatio','rf']

其中，

- ‘num_id’是对股票代码所做的映射，每个股票代码唯一对应着一个整数
- ‘time’是交易日期，由于我们只在每个月的第一天进行调仓，训练样本中的time是每个月的最后一天
- ‘Capitalization’ - ‘TurnoverRatio'为本地数据中给出的10个feature，已进行缺省值处理（整行删除）
- ‘rf’是下一月的超额收益率，即我们通过本月最后一个交易日的个股的features来预测其在下一个月的超额收益率，并在下一个月的第一个交易日就以开盘价进行调仓，之后不再调仓，直到再下一个月

**1.2 训练样本预处理**

主要包括两部分：

- 中位数去极值：
  
    设第T期某feature在所有个股上的暴露度序列为$D_i$, $D_M$为该序列的中位数，$D_{M1}$为序列$|D_i-D_M|$的中位数，则将序列$D_i$中所有大于$D_M+5D_{M1}$的数重设为$D_M+5D_{M1}$， 将序列$D_i$中所有小于$D_M-5D_{M1}$的数重设为$D_M-5D_{M1}$
    
- 标准化：
  
    将中位数去极值后的数据减去现在的均值，除以其标准差，得到一个近似服从$N(0,1)$分布的序列
    

### 2. 模型训练

**2.1 XGBoost简介：**

> XGBoost既可以做分类模型，也可以做回归模型，本项目参照研报中的分类模型进行复现
> 

XGBoost 是 Gradient Boosting 方法的一种高效实现，也是 GBDT 算法的改进和提高。相比于传统的 GBDT 算法，XGBoost 在损失函数、正则化、切分点查找和并行化设计等方面进行了改进，使得其在计算速度上比常见工具包快 5 倍以上。例如，GBDT 算法在训练第 n 棵树时需要用到第 n-1 棵树的残差，从而导致算法较难实现并行；而 XGBoost 通过对目标函数做二阶泰勒展开，使得最终的目标函数只依赖每个数据点上损失函数的一阶导和二阶导，进而容易实现并行。

XGBoost算法流程

<img src="https://github.com/RichardS0268/Quant/blob/main/XGBoost_Stock_Monthly/imgs/Untitled.png" width=60%>

XGBoost主要参数

<img src="https://github.com/RichardS0268/Quant/blob/main/XGBoost_Stock_Monthly/imgs/Untitled%201.png" width=60%>

**2.2 训练集，验证集，测试集的划分**

本项目采用7段回测的方法，进行模型滚动训练

<img src="https://github.com/RichardS0268/Quant/blob/main/XGBoost_Stock_Monthly/imgs/Untitled%202.png" width=60%>

例入将2010-2014年的数据作为样本内数据（训练集和验证集），将2015年的数据作为样本外数据（测试集）

在样本内，采用交叉验证的方式，以9:1的比例划分训练集和测试集。

> 细节：”样本内“的最后一个月（如2014年12月）应划分到测试集中。这是因为我们回测时，如要判断2015年1月的调仓行为，基于的是2014年12月的调仓信号，而2014年12月的数据的label就是2015年的超额收益率的等级，如果将其划入训练集则会造成信息泄露。
> 

**2.3 交叉验证**

本项目借鉴研报中的网格搜索交叉验证，对超参数max_depth和subsample_set进行GridSearch，但发现后者的改变对模型训练结果不起明显作用（这可能是因为每支个股每月只选取了一条数据，总的数据量不大，subsample_set的作用不明显），于是仅对max_depth进行交叉验证，结果如图：

<img src="https://github.com/RichardS0268/Quant/blob/main/XGBoost_Stock_Monthly/imgs/Untitled%203.png" width=40%>


对于其他滚动区间上的模型采取同样的策略，找到较优的超参设定训练模型

**2.4 模型分析**

- 研报利用XGBoost进行二元回归，其label分别是1和-1。其中1代表下一个月的超额收益率在前30%，-1表示下一个月的超额收益率在后30%。经过试验发现，将数据集分成三类（前30%，后30%，其他）分别标为2，0，1，使用多分类模型能达到更高的预测准确率。这是因为使用二分类时，不同个股间的超额收益率的差距会被缩小，模型预测准确率及回测结果都会变差。
- 通过分析各feature的重要度——以其为分割依据的节点的个数，得到如下结果（”xgb-2010-2014”）

<img src="https://github.com/RichardS0268/Quant/blob/main/XGBoost_Stock_Monthly/imgs/Untitled%204.png" width=80%>


**2.5 模型表现**

分7段滚动训练模型，滚动测试后，得出模型的预测准确率，如图

<img src="https://github.com/RichardS0268/Quant/blob/main/XGBoost_Stock_Monthly/imgs/mons_acc.png" width=110%>

### 3. 策略部署与回测

**3.1 交易规则**

- 初始资金1000w
- 买卖交易费用均为交易金额的0.14%
- 为避免冲击成本，规定个股的交易量不能超过其当日总交易量（volumes）的0.0001倍

**3.2 交易流程**

- 每月的最后一个交易日生成“调仓信号”，下一个月的第一个交易日进行调仓，其他时间不进行调仓
- 假设今天是2015年2月的最后一个交易日：
  
    今天 (Day 1)：
    
    > `def generate_signal(...)`
    > 
    1. 读取加载2015年对应的分类模型 → “xgb-2010-2014”
    2. 以今天的所有个股的features值作为模型输入，得到预测的下个月的各个股的月超额收益率的水平（rf_Rank $\in$ (0, 1, 2)）
    3. 筛选出rf_Rank = 2的个股，将其按照今天的市值大小进行排序，将市值最大的n支股票和市值最小的n支股票划入初选集合
    
    明天 (Day 2)：
    
    1. 平仓：将目前持仓中不再初选集合里的股票全部平仓（交易价格为Day 2开盘价），并计算平仓后账户现金额
    2. 建仓：
       
        设定large_leverage比例（如0.2）
        
        1. 建小市值股票仓：将cost1 = 账户现金额*（1-large_leverage）平均分配到n支初选集合中的小市值股票上，由于交易量的限制以及可能该股票不能交易（反映为本地数据Price中相应个股相应日期的Open为nan），实际花费会小于cost1 ⇒ `def Short(...)`
        2. 将cash - cost1 平均分配到n支初选集合中的大市值股票上，同理，实际花费也会小于cash - cost1 ⇒ `def Long(...)`
        3. 计算账户总额 `def Accounting(...)` ，因为我们是月度调仓，因此，
           
            月末的账户总值=月末小市值股票仓价值（各股票持仓量*月末交易日的收盘价） + 月末大市值股票仓价值（各股票持仓量*月末交易日的收盘价） + 剩余现金
            

**3.3 比较基准**

- 将沪深300作为比较基准，交易规则相同。
- baseline的调仓方式为：每一期买入剩余现金所能购买的沪深300的最大数量，长期持有，不平仓。同理计算baseline的每月月末的账户总额

回测结果如图，

<img src="https://github.com/RichardS0268/Quant/blob/main/XGBoost_Stock_Monthly/imgs/backtest.png" width=110%>

### 4. 总结

- 本项目从原生数据出发，完整实现了数据处理，模型训练，策略部署与回测的过程
- GBDT模型在数据竞赛中很常用，其在结构化数据的分类和回归问题上具有很强的能力，XGBoost是GBDT中的一种经典的模型，在本项目所用数据量较少的情况下仍有相对可观的准确率

**改进方向**

1. 本项目将股票数据进行结构化处理的同时破坏了其时序关系，结构化后的训练数据失去了时间序列上的信息
2. 本策略的换仓频率较低，导致本地数据中的绝大部分数据没有得到利用，增加的训练数据量可在一定程度上提升模型预测准确率及回测结果
